---
title: "9.6 Lab support vector machines"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## 9.6.1 support vector classifier
### plane not separable
```{r}
set.seed(1)
x <- matrix(rnorm(20*2), ncol = 2)
y <- c(rep(-1, 10), rep(1, 10))
x[y==1, ] = x[y==1, ] + 1
plot(x, col=(3-y))
```
```{r}
dat <- data.frame(x=x, y=as.factor(y))
library(e1071)
svmfit <- svm(y~., data=dat, kernel="linear", cost=10, scale = FALSE)
plot(svmfit, dat)
```
```{r}
summary(svmfit)
```
```{r}
svmfit <- svm(y~., data = dat, kernel="linear", cost=0.1, scale = FALSE)
plot(svmfit, dat)
```
```{r}
svmfit$index
```
```{r}
set.seed(1)
turn.out <- tune(svm, y~., data = dat, kernel="linear", ranges = list(cost=c(0.001, 0.01, 0.1, 1.5, 10, 100)))
summary(turn.out)
```
```{r}
bestmod <- turn.out$best.model
summary(bestmod)
```
```{r}
set.seed(1)
xtest <- matrix(rnorm(20*2), ncol=2)
ytest <- sample(c(-1, 1), 20, rep=TRUE)
xtest[ytest==1, ] = xtest[ytest == 1, ] +1
testdat <- data.frame(x=xtest, y=as.factor(ytest))
```
```{r}
ypred <- predict(bestmod, testdat)
table(predict=ypred, truth=testdat$y)
```
```{r}
svmfit <- svm(y~., data = dat, kernel="linear", cost=0.01, scale = FALSE)
ypred <- predict(svmfit, testdat)
table(predict=ypred, truth=testdat$y)
```
### plane separable
```{r}
x[y==1, ]=x[y==1, ] + 0.5
plot(x, col=(y + 5)/2, pch=19)
```
```{r}
dat <- data.frame(x=x, y=as.factor(y))
svmfit <- svm(y~., data=dat, kernel="linear", cost=1e5, scale = FALSE)
summary(svmfit)
```

```{r}
plot(svmfit, dat)
```
```{r}
svmfit <- svm(y~., data=dat, kernel="linear", cost=1, scale = FALSE)
summary(svmfit)
```
```{r}
plot(svmfit, dat)
```
## 9.6.2 support vector machine
```{r}
set.seed(1)
x <- matrix(rnorm(200*2), ncol=2)
x[1:100,] = x[1:10,] + 2
x[101:150,] = x[101:150,] - 2
y = c(rep(1, 150), rep(2, 50))
dat <- data.frame(x=x, y=as.factor(y))
plot(x, col=y)
```

```{r}
train <- sample(200, 100)
svmfit <- svm(y~., data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmfit, dat[train, ])
```
```{r}
summary(svmfit)
```
```{r}
svmfit <- svm(y~., data=dat[train,], kernel="radial", gamma=1, cost=1e5)
plot(svmfit, dat[train, ])
```
```{r}
set.seed(1)
tune.out <- tune(svm, y~., data = dat[train,], kernel="radial", ranges = list(cost=c(0.1, 1, 10, 100, 1000), gamma=c(0.5, 1, 2, 3, 4)))
summary(tune.out)
```
```{r}
table(true=dat[-train, "y"], pred=predict(tune.out$best.model, newdata=dat[-train,]))
```

```{r}
library(ROCR)
rocplot <- function(pred, truth, ...){
  predob=prediction(pred, truth)
  perf=performance(predob, "tpr", "fpr")
  plot(perf, ...)
}
```
```{r}
svmfit.opt <- svm(y~., data=dat[train,], kernel="radial", gamma=2, cost=1, decision.values=TRUE)

fitted <- attributes(predict(svmfit.opt, dat[train, ], decision.values=TRUE))$decision.values
rocplot(fitted, dat[train, "y"], main="Training Data")
```
```{r}
svmfit.flex <- svm(y~., data=dat[train,], kernel="radial", gamma=50, cost=1, decision.values=TRUE)

fitted <- attributes(predict(svmfit.flex, dat[train, ], decision.values=TRUE))$decision.values

rocplot(fitted, dat[train, "y"], col="red", main="Training Data")
```
```{r}
fitted <- attributes(predict(svmfit.opt, dat[-train, ], decision.values=TRUE))$decision.values
rocplot(fitted, dat[-train, "y"], main="Test Data")
```
```{r}
fitted <- attributes(predict(svmfit.flex, dat[-train, ], decision.values=TRUE))$decision.values

rocplot(fitted, dat[-train, "y"], col="red", main="Test Data")
```

